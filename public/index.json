
[{"content":"","date":"21 July 2025","externalUrl":null,"permalink":"/","section":"Niyuta's Blog","summary":"","title":"Niyuta's Blog","type":"page"},{"content":"","date":"21 July 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":" EAI Review # 宇树具身智能社群\nVLA # 知乎VLA综述\n具身智能中 VLA 主流方案全解析：技术总结与未来展望-CSDN博客\nVLA 任务依靠视觉 - 语言 - 动作模型，输入是视觉 - 语言，生成动作序列。本质上是一个生成式多模态任务，跟咱们实验室的研究方向比较搭。但是与其他多模态任务不同的是硬件要求比较大。\n硬件需求：机械臂，GPU 算力要求非常大。\n经典方案如下。从下面的技术方案就可以看出 VLA 也是个搭网络、训练/微调大模型的活。\n基于经典 Transformer 结构的方案，如 ALOHA(ACT) 系列、RT-1、HPT 等，利用 Transformer 的序列建模能力，将强化学习轨迹建模为状态 - 动作 - 奖励序列，提升复杂环境下的决策能力； 基于预训练 LLM/VLM 的方案，如 RT-2、OpenVLA 等，将 VLA 任务视为序列生成问题，借助预训练模型处理多模态信息并生成动作，增强泛化性和指令理解能力； 基于扩散模型的方案，如 Diffusion Policy、RDT-1B 等，通过去噪扩散概率模型生成动作，适用于高维动作空间和复杂动作分布； LLM+ 扩散模型方案，如 Octoπ0 等，结合 LLM 的多模态表征压缩与扩散模型的动作生成能力，提高复杂任务中的性能； 视频生成 + 逆运动学方案，如 UniPiRo、BoDreamer 等，先生成运动视频再通过逆运动学推导动作，提升可解释性和准确性； 显式端到端方案直接将视觉语言信息映射到动作空间，减少信息损失； 隐式端到端方案，如 SWIM 等，利用视频扩散模型预测未来状态并生成动作，注重知识迁移； **分层端到端方案，**结合高层任务规划与低层控制，提升长时域任务的执行效率。 个人觉得 VLA 里能做的非常多，探索空间也很大，难度也很高。目前完成度很好的是下面提到的 $\\pi_0$ 模型，被博客作者认为是机器人的大模型时代。\nPaper List # π0——用于通用机器人控制的VLA模型：一套框架控制7种机械臂(基于PaliGemma和流匹配的3B模型)-CSDN博客 π系列知乎解读 数据集 #dataset # [Open X-Embodiment dataset (OEX 数据集)](https://robotics-transformer-x.github.io/ Open X-Embodiment（OXE）dataset VLN # VLN 任务（是任务而不是模型，因为通常包含很多模型的协同）将视觉信息和语言指令作为输入，输出包括导航动作和目标识别。\n个人感觉 VLN 要比后文提到的 VLA 更简单一点，任务也更固定和明确。但是简单不代表好做，难点在于大模型和小模型的协同（这就导致 VLN 任务像一个工程化的任务）。就目前的方法论而言，零样本、零训练的模型在近几年出现得比较多，思想基本是 LLM 和视觉模型割裂开进行协作。我觉得创新的角度也比较多。\n硬件要求：需要一个能跑、头上摄像头能转的小机器人。GPU 算力要求取决于方法，如果方法要训练 LLM 或者 VLM 那就很吃算力，如果方法是零样本的、只需要部署 LLM 模型，那算力要求就很小。比如 UniGoal 只需要两个 3090 就能运行。\nPaper List # Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models 【机器人】具身导航 VLN 最新论文汇总 | Vision-and-Language Navigation-CSDN博客 CVPR2025 | UniGoal：通用零样本目标导航，Navigate to Any Goal! 这个有点强，因为给 llm 的是纯文本描述，所以不用预训练。 WMNav：融合VLM和世界模型的室内目标导航 NeurIPS-2024 | 具备人类感知能力的具身导航智能体！HA-VLN：通过人类动态交互连接仿真与现实世界 Real-to-Sim, Sim-to-Real, Real-to-Sim-to-Real # 这个很有意思，我感觉属于传统机器人控制的方向，具身智能综述里关于这方面的内容比较少。但是我看最近的 paper 也一直在接受，而且还不少。这些方面和强化学习的结合比较多。\nReal-to-Sim 主要是三维重建，Sim-to-Real 主要是使得在仿真环境中训练的机器人，能在现实中运行起来。这一块儿理论方法很多，数学推导也很多。\nRea-to-Sim-to-Real 的任务比较杂，落脚点（模型输出）是机器人的动作，让机器人完成姿态控制和导航等任务，比如让人形机器人/四足狗爬楼梯等等。出发点（或者说模型的输入）就很多样，比如用视频训练机器人。\n硬件：人形机器人、机器狗等，根据不同的任务而定。GPU 算力需求也是强化学习的需求，根据任务有大有小。\nPaper List # VR-Robo: A Real-to-Sim-to-Real Framework for Visual Robot Navigation and Locomotion VideoMimic ","date":"21 July 2025","externalUrl":null,"permalink":"/posts/eai/eai-review/","section":"Posts","summary":"","title":"做个具身智能的Review","type":"posts"},{"content":"","date":"21 July 2025","externalUrl":null,"permalink":"/tags/cornerstone/","section":"Tags","summary":"","title":"Cornerstone","type":"tags"},{"content":"","date":"21 July 2025","externalUrl":null,"permalink":"/tags/idea/","section":"Tags","summary":"","title":"Idea","type":"tags"},{"content":"","date":"21 July 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":" 信息瓶颈理论 # 信息瓶颈理论\nVAE 隐变量的维度问题 # Kimi - 会推理解析，能深度思考的AI助手\n有的。目前对 VAE“到底能把维度压到多低才崩” 已经有 信息论层面的严格推导，而且路径不止一条，可以归纳为“三条主线 + 一张统一框架图”。\n1. 信息瓶颈（IB）视角：β-VAE 的闭式最优维度 # β-VAE 的目标可改写成信息瓶颈形式\n$$ \\min_{q(z|x)} \\; \\underbrace{I_q(z;x)}_{\\text{压缩项}} - \\beta I_q(z;y) $$ Alemi et al. (2018) 在高斯 - 线性假设下给出了解析解： 最优隐维度 = $rank(Σ_x) − rank(Σ_{x|y})$ 即“输入协方差秩 − 冗余协方差秩”。 对图像数据可近似为 $d\\ ≈ d_data − d_noise$，实验上 CIFAR-10 的 d*≈10～12 维 。 当实际维度 n \u0026lt; d* 时，ELBO 开始指数恶化。 2. 率 - 失真 - 维度（R-D-n）曲面 # 把 ELBO 拆成\n$$ \\mathcal L = -D + R,\\quad R = \\mathbb E_x \\Bigl[\\operatorname{KL}(q_\\phi(z|x)\\|p(z))\\Bigr] $$ 理论结果：在渐进高斯源假设下，有\n$$ D(n) = \\sigma^2\\,\\Bigl(1+\\tfrac{n}{2}\\Bigr)^{-2/n} + o(1) $$当 n→0 时失真 D→σ²（完全噪声），拐点 n* 满足\n$$ n^* \\approx \\log_2\\!\\bigl(\\tfrac{\\sigma^2}{\\epsilon}\\bigr) $$其中 ε 为可容忍失真。 实验验证：ImageNet 64×64 的 VAE 在 n\u0026lt;256 时 FID 陡增，与理论拐点基本一致 3. 数据内在维度（ID）下界 # 先用 TwoNN 或 MLE 估计数据本身的内在维度 d₀（CIFAR-10≈20）。\n文献给出经验不等式 $$ n_{\\text{safe}} \\gtrsim \\tfrac{d_0}{3} $$当 n \u0026lt; d₀/3 时，重构误差迅速恶化 。\n4. 统一框架：深度多变量信息瓶颈（DMIB） # 最新工作把 β-VAE、DVIB、DVCCA 全部吸收进一个 多变量信息瓶颈损失，并给出 闭式最优维度 的通式 ：\n$$ n^* = \\arg\\min_n \\Bigl\\{ I(z;x) - \\beta I(z;y) + \\gamma n \\Bigr\\} $$通过调 β、γ 即可解析得到不同任务下的“压缩极限”。\n小结：如何落地 # 快速估计 用 TwoNN 算 d₀ → 取 n ≈ d₀/3 作为下限。 精细计算 线性高斯假设下套用 Alemi 公式；非线性网络则用 DMIB 框架做梯度优化。 实验验证 在 β-VAE 上做 R-D-n 扫描，找到 FID 或 ELBO 开始指数恶化的拐点即可。 这些推导都已集成进开源库 dvib-pytorch 与 pytorch-msssim，可直接跑通。\n","date":"21 July 2025","externalUrl":null,"permalink":"/posts/aigc/%E4%BF%A1%E6%81%AF%E7%93%B6%E9%A2%88%E7%90%86%E8%AE%BA%E4%BA%92%E4%BF%A1%E6%81%AFmutual-informationvae%E9%9A%90%E5%8F%98%E9%87%8F%E7%9A%84%E7%BB%B4%E5%BA%A6/","section":"Posts","summary":"","title":"VAE隐变量最多多少维度？","type":"posts"},{"content":"我觉得 Score matching by Andy Jones 说得挺清楚了，所以这一篇笔记主要是回忆性质，记下几个 key point 和 key idea。\nScore-matching 要解决的问题是？ 如何理解 Score 函数？Score 函数是如何解决 normalizing constant 的问题的？ 如何衡量两个分布的梯度的差距？为什么用 Fisher 散度？ 为什么涉及到真实分布 $p_d(x)$ 的就不好求？ 🙋什么是 Score Matching？ # Score Matching Score Matching 是一种用于拟合统计模型的方法，特别适用于处理不可计算归一化常数（intractable normalizing constants）的模型。在机器学习中，当模型的似然函数复杂且难以归一化时（例如在能量基模型（EBMs）、生成对抗网络（GANs）或变分自编码器（VAEs 中），Score Matching 提供了一种绕过归一化常数的方法来优化模型参数。\n假设我们有一组观测数据 $x_1, \\dots, x_n$，这些数据服从未知的真实分布 $p_d(x)$。我们希望用一个参数化的模型 model 分布 $p_m(x; \\theta)$ 来近似 distribution $p_d(x)$，其中 $\\theta$ 是模型参数。目标是找到合适的 $\\theta$，使 $p_m(x; \\theta)$ 尽可能接近 $p_d(x)$。 在最大似然估计（MLE）中，我们通常通过最大化数据的对数似然来优化 $\\theta$：\n$$ \\widehat{\\theta}_{MLE} = argmax_{\\theta} \\log p_m(x; \\theta). $$模型的概率密度函数通常可以写成未归一化的密度 $\\widetilde{p}(x; \\theta)$ 和归一化常数 $Z_\\theta$ 的形式：\n$$ p_m(x; \\theta) = \\frac{\\widetilde{p}(x; \\theta)}{Z_\\theta}, \\quad Z_\\theta = \\int_{\\mathcal{X}} \\widetilde{p}(x; \\theta) , dx. $$这里的 $Z_\\theta$ 是一个 normalizing constant，通常在复杂模型中难以计算（即不可解，intractable）。Score Matching 的核心思想是通过避免直接计算 $Z_\\theta$，来解决这一问题。\n我觉得这里完全有必要说一下：难在哪儿？为什么不能求出 $p_d(x)$？ Note 因为真实分布只有样本，没有分布，我们可以假设模型分布 $p_m$ 为高斯啦学生分布啦等等，但是真实分布通常有可能是高斯混合模型，很难搞。所以我们得想办法消除 $p_d(x)$ 这一项。在后文中还会出现一次 $p_{m}$ 项，留意之。\n💡Score Matching 的核心思想 # 其实我们如果注意到，对上面的 model 分布 p 对 x 求梯度，那么 Z 这一项就会消失（因为参数里没有 x）。 在 Score Matching 中，==score 函数==是指对数似然函数关于数据 $x$ 的梯度：\n$$ \\nabla_x \\log p_m(x; \\theta). $$将其展开，我们可以看到归一化常数的优势：\n$$ \\nabla_x \\log p_m(x; \\theta) = \\nabla_x \\log \\widetilde{p}_m(x; \\theta) - \\nabla_x \\log Z_\\theta. $$由于 $Z_\\theta$ 不依赖于 $x$，其梯度 $\\nabla_x \\log Z_\\theta = 0$，因此：\n$$ \\nabla_x \\log p_m(x; \\theta) = \\nabla_x \\log \\widetilde{p}_m(x; \\theta). $$Normalizing constant Z 消失了！那么 Score matching 的核心思想变呼之欲出：如果建模分布 $p_m$ 与原始分布 $p_d$ 相似，那么他们的梯度也应该相似。最后顶多差一个偏移而已。\n🎯Score Matching 的目标 # Score Matching 的目标是最小化模型分布的 score 函数与真实数据分布的 score 函数之间的 Fisher 散度（Fisher Divergence）：\n$$ \\widehat{\\theta}_{SM} = argmin_{\\theta} D_F(p_d, p_m) = argmin_{\\theta} \\frac{1}{2} \\mathbb{E}_{p_d} \\left[ | \\nabla_x \\log p_d(x) - \\nabla_x \\log p_m(x; \\theta) |_2^2 \\right]. $$ 这是因为只有 fisher 散度可以跟梯度联系起来，而 KL 散度是做不到的。 但到了这里还是有 $p_d(x)$ 项，还是不好求。所以自然地想到下一步要怎么做。\n↻绕过归一化常数和数据分布 # 展开 Fisher 散度： $$ \\frac{1}{2} | \\nabla_x \\log p_d(x) - \\nabla_x \\log p_m(x; \\theta) |_2^2 = \\frac{1}{2} (\\nabla_x \\log p_d(x))^2 - \\nabla_x \\log p_m(x; \\theta) \\nabla_x \\log p_d(x) + \\frac{1}{2} (\\nabla_x \\log p_m(x; \\theta))^2. $$ 第一项 $\\frac{1}{2} (\\nabla_x \\log p_d(x))^2$ 是常数项，不依赖 $\\theta$，不影响优化 $\\theta$，可以忽略。 第三项 $\\frac{1}{2} (\\nabla_x \\log p_m(x; \\theta))^2$ 可以通过数据样本直接估计，因为它不依赖 $p_d(x)$。 处理交叉项： $$ \\mathbb{E}_{p_d} \\left[ -\\nabla_x \\log p_m(x; \\theta) \\nabla_x \\log p_d(x) \\right] = -\\int_{-\\infty}^{\\infty} \\nabla_x \\log p_m(x; \\theta) \\nabla_x \\log p_d(x) p_d(x) , dx. $$通过分部积分法（integration by parts）（这里很巧妙但是我不细写了），假设边界项在无穷远处消失（即 $p_d(x) \\nabla_x \\log p_m(x; \\theta) \\to 0$ 当 $|x|_2 \\to \\infty$），我们可以将交叉项转化为：\n$$ \\int_{-\\infty}^{\\infty} \\nabla_x^2 \\log p_m(x; \\theta) p_d(x) dx. $$那么问题来了：==为什么会假设边界项消失？==\n边界项消失 边界项 $p_d(x) \\nabla_x \\log p_m(x; \\theta) \\to 0$ 当 $|x|_2 \\to \\infty$ 是一个正则化条件，确保分部积分成立。直观上：\n数据分布 $p_d(x)$ 通常在无穷远处迅速衰减到零，因为实际数据集中在有限区域，尾部概率很小。例如高斯分布 $p_d(x) \\propto \\exp(-x^2 / (2\\sigma_d^2))$ 的尾部以指数速度衰减。 模型 score 函数 $\\nabla_x \\log p_m(x; \\theta)$ 通常增长较慢（例如高斯模型中为线性增长）。因此，乘积 $p_d(x) \\nabla_x \\log p_m(x; \\theta)$ 在无穷远处趋于零，因为数据分布的尾部衰减比 score 函数的增长快。 这就像在积分中，尾部贡献变得微不足道，因为数据分布在无穷远处几乎没有概率质量。 在高斯分布的例子中：\n$$ p_d(x)\\nabla_x \\log p_m(x;\\mu,\\sigma^2) \\sim \\exp\\!\\left(-\\frac{x^{2}}{2\\sigma_d^{2}}\\right)\\cdot\\frac{\\mu-x}{\\sigma^{2}} \\to 0 $$因为指数衰减比线性增长快得多。\n因为 $\\nabla_x^2 \\log p_m(x; \\theta) p_d(x) dx$ 在大于等于 2 阶情况下的其实是个 Hessian 矩阵，对角线的元素才是对 x 求二阶导，所以写成 tr 的形式 $$ \\int_{-\\infty}^{\\infty} \\nabla_x^2 \\log p_m(x; \\theta) p_d(x) dx = \\mathbb{E}_{p_d} \\left[ \\text{tr} \\left( \\nabla_x^2 \\log p_m(x; \\theta) \\right) \\right] $$所以损失函数：\n$$ D_F(p_d, p_m) \\propto L(\\theta) = \\mathbb{E}_{p_d} \\left[ \\text{tr} \\left( \\nabla_x^2 \\log p_m(x; \\theta) \\right) + \\frac{1}{2} ||\\nabla_x \\log p_m(x; \\theta)||_2^2 \\right]. $$使用数据样本 $x_1, \\dots, x_n$，目标函数可近似为：\n$$ L(\\theta) \\approx \\frac{1}{n} \\sum_{i=1}^n \\left[ \\text{tr} \\left( \\nabla_x^2 \\log p_m(x_i; \\theta) \\right) + \\frac{1}{2} |\\nabla_x \\log p_m(x_i; \\theta)|_2^2 \\right]. $$这个目标函数完全不依赖归一化常数 $Z_\\theta$ 和真实分布 $p_d(x)$，只需要模型的未归一化密度 $\\widetilde{p}_m(x; \\theta)$ 和数据样本即可。 Hyvärinen 证明，如果真实分布 $p_d(x) = p_m(x; \\theta^\\star)$ 属于模型族，则优化 $L(\\theta)$ 可找到最优参数 $\\theta^\\star$。\n只要真实分布 恰好能被模型族中的某个参数 $\\theta^\\star$ 表示出来，那么最小化得分匹配目标 $L(θ)$ 就一定能把这个 $\\theta^\\star$ 找出来。\n🤔目标函数的直观理解 # 目标函数由两部分组成：\nNorm 项：$\\frac{1}{2} |\\nabla_x \\log p_m(x_i; \\theta)|_2^2$ 表示模型 score 函数的大小。 当数据点 $x_i$ 被模型很好地解释时（即位于似然的高概率区域），score 函数的值较小（似然变化平缓）。 直观上，这个项希望模型的似然函数在数据点附近平滑。 Hessian 项：$\\text{tr} \\left( \\nabla_x^2 \\log p_m(x_i; \\theta) \\right)$ 表示对数似然的二阶导数（Hessian 矩阵的迹）。 如果数据点位于“尖锐”的局部极小值处（Hessian 迹为负且绝对值较大），说明模型对数据的解释更“独特”。 直观上，这个项倾向于选择更“尖锐”的似然函数，避免过于平坦的似然（平坦的似然意味着多种参数值都能解释数据）。 这两个项相互平衡：Norm 项倾向于平滑的似然，Hessian 项倾向于尖锐的似然，优化 $L(\\theta)$ 找到既能解释数据又具有适当曲率的模型。\n📖方法论 # 所以总结一下，最后其实很简单——甚至损失函数只和 $p_m$ 有关。假设了 $p_m$ 的分布之后：\n先求其关于训练数据的一阶导数的平方（Norm 项） 再在 Norm 项算式的基础上求其二阶导（Hessian 项） 相加，求 $argmin_{\\theta}$，就完事儿了。Score matching by Andy Jones 的最后举了一个高斯的例子，很不错。 📚 延伸阅读 # Hyvärinen (2005): 原始论文，提出得分匹配。 Song \u0026amp; Ermon (2019): 使用得分匹配进行生成建模。 Sliced Score Matching (2020): 可扩展版本，适用于高维数据。 ","date":"21 July 2025","externalUrl":null,"permalink":"/posts/aigc/score-matching/","section":"Posts","summary":"","title":"Score matching详解！","type":"posts"},{"content":" About Me # Hi, this is Niyuta ✨\n🎓 Education # M.S. in Deep Learning @ Beihang University (BUAA) B.S. in Computer Science @ Beihang University (BUAA) 💻 Technical Stack # Languages \u0026amp; Tools:\nProficient: Python, Rust (perhaps) Familiar: Java, C#, JavaScript/TypeScript, C/C++, SQL Misc: Git, Docker, Linux, Qemu, Cloud, React, Vue, etc. 🔭 Current Interests # Machine Learning \u0026amp; Deep Learning Systems (Python 🐍) High-performance Computing (Rust 🦀) Operating Systems (Rust 🦀) Web Development (React \u0026amp; Vue \u0026amp; Go 🎉) 🎸 Beyond Code # Guitarist crafting riffs when not debugging Anime cosplayer bringing 2D to 3D Eternal student of math \u0026amp; physics ","date":"28 February 2019","externalUrl":null,"permalink":"/page/about/","section":"Pages","summary":"","title":"About","type":"page"},{"content":"","date":"28 February 2019","externalUrl":null,"permalink":"/page/","section":"Pages","summary":"","title":"Pages","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]